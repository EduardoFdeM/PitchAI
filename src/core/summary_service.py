"""
Post-Call Summary Service - Feature 5
====================================

Servi√ßo unificado para gera√ß√£o de resumos executivos p√≥s-chamada.
Consolida dados de transcri√ß√£o, sentimento, obje√ß√µes e gera resumo via LLM local.
"""

import json
import uuid
import logging
from datetime import datetime
from typing import Dict, List, Optional, Any
from dataclasses import dataclass
from PyQt6.QtCore import QObject, pyqtSignal, QThread

@dataclass
class CallSummary:
    """Estrutura do resumo p√≥s-chamada"""
    call_id: str
    key_points: List[str]
    objections: List[Dict[str, Any]]
    next_steps: List[Dict[str, Any]]
    metrics: Dict[str, Any]
    generated_at: float

class PostCallSummaryService(QObject):
    """Servi√ßo unificado para gera√ß√£o de resumo p√≥s-chamada"""

    summary_ready = pyqtSignal(CallSummary)
    summary_error = pyqtSignal(str)

    def __init__(self, config, llm_service=None, storage_service=None):
        super().__init__()
        self.config = config
        self.logger = logging.getLogger(__name__)
        self.llm_service = llm_service
        self.storage_service = storage_service

        # Fallback: criar LLM Service se n√£o fornecido
        if self.llm_service is None:
            try:
                from ai.llm_service import LLMService
                self.llm_service = LLMService(
                    model_dir=config.app_dir / "models",
                    use_simulation=False,
                    use_anythingllm=True
                )
                self.llm_service.initialize()
                self.logger.info("‚úÖ LLM Service criado no SummaryService")
            except Exception as e:
                self.logger.warning(f"‚ö†Ô∏è N√£o foi poss√≠vel criar LLM Service: {e}")
                self.llm_service = None

    def generate(self, call_id: str) -> Optional[CallSummary]:
        """Gera resumo executivo da chamada"""
        # 1. Consolidar dados da chamada
        call_data = self._consolidate_call_data(call_id)

        # 2. Verificar se LLM Service est√° dispon√≠vel
        if not self.llm_service:
            self.logger.warning("‚ö†Ô∏è LLM Service n√£o dispon√≠vel, usando resumo simulado")
            return self._generate_fallback_summary(call_data)

        # 3. Gerar prompt estruturado
        prompt = self._build_summary_prompt(call_data)

        # 4. Invocar LLM local (AnythingLLM)
        try:
            llm_response = self.llm_service.generate_response(prompt, max_tokens=1000)
            self.logger.info("‚úÖ Resumo gerado com AnythingLLM")
        except Exception as e:
            self.logger.warning(f"‚ö†Ô∏è Erro no LLM, usando fallback: {e}")
            return self._generate_fallback_summary(call_data)

        # 5. Parsear resposta estruturada
        summary = self._parse_llm_response(llm_response, call_id)

        # 6. Persistir no storage
        if self.storage_service:
            # TODO: Implementar salvamento s√≠ncrono
            pass

        return summary

    def _generate_fallback_summary(self, call_data: Dict[str, Any]) -> CallSummary:
        """Gera resumo fallback quando LLM n√£o est√° dispon√≠vel"""
        self.logger.info("üîÑ Gerando resumo fallback...")

        # Resumo b√°sico baseado nos dados consolidados
        transcript = call_data.get("transcript", "")
        sentiment = call_data.get("sentiment_data", {})
        objections = call_data.get("objections", [])

        # Pontos principais simulados
        key_points = [
            "Reuni√£o realizada com cliente potencial",
            "Discuss√£o sobre necessidades e solu√ß√µes",
            "Apresenta√ß√£o de benef√≠cios da proposta"
        ]

        # Pr√≥ximos passos simulados
        next_steps = [
            {
                "desc": "Enviar proposta detalhada por email",
                "due": "2025-01-20",
                "owner": "vendedor"
            },
            {
                "desc": "Agendar demonstra√ß√£o t√©cnica",
                "due": "2025-01-25",
                "owner": "vendedor"
            }
        ]

        # M√©tricas simuladas
        metrics = {
            "talk_time_vendor_pct": 45.0,
            "talk_time_client_pct": 55.0,
            "sentiment_avg": sentiment.get("avg_score", 0.7),
            "objections_total": len(objections),
            "objections_resolved": len([obj for obj in objections if obj.get("handled", False)]),
            "buying_signals": sentiment.get("buying_signals_count", 2)
        }

        # Obje√ß√µes tratadas
        objections_summary = []
        for obj in objections:
            objections_summary.append({
                "type": obj.get("type", "unknown"),
                "handled": obj.get("handled", False),
                "note": obj.get("note", "")
            })

        return CallSummary(
            call_id=call_data.get("call_id", "unknown"),
            key_points=key_points,
            objections=objections_summary,
            next_steps=next_steps,
            metrics=metrics,
            generated_at=datetime.now().timestamp()
        )
    
    def _consolidate_call_data(self, call_id: str) -> Dict[str, Any]:
        """Consolida dados de transcri√ß√£o, sentimento e obje√ß√µes"""
        # Dados simulados para teste
        return {
            "transcript": {
                "chunks": [
                    {"speaker": "vendor", "text": "Ol√°, bom dia! Como vai?", "duration_sec": 2.0},
                    {"speaker": "client", "text": "Oi, tudo bem. Gostaria de saber sobre a solu√ß√£o", "duration_sec": 3.0},
                    {"speaker": "vendor", "text": "Claro! Nossa plataforma oferece integra√ß√£o completa", "duration_sec": 4.0},
                    {"speaker": "client", "text": "Parece interessante, mas est√° muito caro", "duration_sec": 2.5},
                    {"speaker": "vendor", "text": "Entendo sua preocupa√ß√£o. O ROI √© de 340% em 18 meses", "duration_sec": 5.0},
                    {"speaker": "client", "text": "Hmm, preciso pensar melhor", "duration_sec": 2.0}
                ],
                "text": "Transcri√ß√£o de exemplo da reuni√£o"
            },
            "sentiment_data": {"avg_score": 0.75},
            "objections": [{"type": "preco", "handled": True}],
            "call_id": call_id,
            "metrics": {
                "talk_time_vendor_pct": 55.0,
                "talk_time_client_pct": 45.0,
                "sentiment_avg": 0.75,
                "objections_total": 1,
                "objections_resolved": 1,
                "buying_signals": 2
            }
        }
    
    def _calculate_metrics(self, transcript, sentiment_data, objections) -> Dict[str, Any]:
        """Calcula KPIs da chamada"""
        total_duration = transcript.get("duration_sec", 0)
        vendor_talk_time = sum(
            chunk.get("duration_sec", 0) 
            for chunk in transcript.get("chunks", [])
            if chunk.get("speaker") == "vendor"
        )
        
        return {
            "talk_time_vendor_pct": (vendor_talk_time / total_duration * 100) if total_duration > 0 else 0,
            "talk_time_client_pct": 100 - (vendor_talk_time / total_duration * 100) if total_duration > 0 else 0,
            "sentiment_avg": sentiment_data.get("average_sentiment", 0),
            "objections_total": len(objections),
            "objections_resolved": len([obj for obj in objections if obj.get("handled", False)]),
            "buying_signals": sentiment_data.get("buying_signals_count", 0)
        }
    
    def _build_summary_prompt(self, call_data: Dict[str, Any]) -> str:
        """Constr√≥i prompt estruturado para o LLM"""
        transcript_text = self._extract_transcript_text(call_data["transcript"])
        objections_text = self._format_objections(call_data["objections"])
        metrics = call_data["metrics"]
        
        prompt = f"""
        Voc√™ √© um assistente de IA especializado em an√°lise de chamadas de vendas. Analise a transcri√ß√£o abaixo e gere um resumo executivo inteligente focado em vendas.

        CONTEXTO DA CHAMADA:
        Esta √© uma chamada de vendas onde um vendedor est√° conversando com um cliente potencial. Voc√™ deve identificar oportunidades, obje√ß√µes, sinais de compra e pr√≥ximos passos estrat√©gicos.

        TRANSCRI√á√ÉO DA CHAMADA:
        {transcript_text}

        OBJE√á√ïES DETECTADAS:
        {objections_text}

        M√âTRICAS T√âCNICAS:
        - Tempo de fala vendedor: {metrics['talk_time_vendor_pct']:.1f}%
        - Tempo de fala cliente: {metrics['talk_time_client_pct']:.1f}%
        - Sentimento m√©dio: {metrics['sentiment_avg']:.2f}
        - Obje√ß√µes totais: {metrics['objections_total']}
        - Obje√ß√µes resolvidas: {metrics['objections_resolved']}
        - Sinais de compra detectados: {metrics['buying_signals']}

        INSTRU√á√ïES PARA AN√ÅLISE:
        1. **Pontos Principais**: Extraia os 3-5 pontos mais importantes da conversa (necessidades do cliente, benef√≠cios discutidos, decis√µes tomadas)
        2. **Obje√ß√µes**: Para cada obje√ß√£o, indique se foi tratada e como
        3. **Pr√≥ximos Passos**: Sugira a√ß√µes concretas com datas e respons√°veis
        4. **An√°lise Estrat√©gica**: Considere o contexto de vendas - sinais de interesse, urg√™ncia, autoridade de decis√£o

        FORMATO DE SA√çDA (JSON puro, sem formata√ß√£o adicional):
        {{
            "key_points": ["Ponto principal 1", "Ponto principal 2", "Ponto principal 3"],
            "objections": [
                {{"type": "preco", "handled": true, "note": "Explicado ROI de 340% em 18 meses"}},
                {{"type": "timing", "handled": false, "note": "Cliente precisa aprovar com equipe t√©cnica"}}
            ],
            "next_steps": [
                {{"desc": "Enviar proposta t√©cnica detalhada", "due": "2025-01-17", "owner": "vendedor", "priority": "alta"}},
                {{"desc": "Agendar demonstra√ß√£o para equipe t√©cnica", "due": "2025-01-24", "owner": "vendedor", "priority": "media"}},
                {{"desc": "Preparar case study similar", "due": "2025-01-18", "owner": "vendedor", "priority": "baixa"}}
            ],
            "metrics": {{
                "talk_time_vendor_pct": {metrics['talk_time_vendor_pct']},
                "talk_time_client_pct": {metrics['talk_time_client_pct']},
                "sentiment_avg": {metrics['sentiment_avg']},
                "objections_total": {metrics['objections_total']},
                "objections_resolved": {metrics['objections_resolved']},
                "buying_signals": {metrics['buying_signals']}
            }},
            "insights": {{
                "cliente_interesse": "alto|m√©dio|baixo",
                "urgencia": "alta|m√©dia|baixa",
                "autoridade_decisao": "tomador|influenciador|usuario",
                "proxima_acao_recomendada": "follow_up|proposta|demo|nurturing"
            }}
        }}

        LEMBRE-SE: Foque no contexto comercial e nas oportunidades de venda. Seja espec√≠fico e acion√°vel.
        """
        return prompt
    
    def _extract_transcript_text(self, transcript: Dict[str, Any]) -> str:
        """Extrai texto da transcri√ß√£o formatado"""
        chunks = transcript.get("chunks", [])
        text_parts = []
        
        for chunk in chunks:
            speaker = chunk.get("speaker", "unknown")
            text = chunk.get("text", "")
            if text.strip():
                text_parts.append(f"{speaker.upper()}: {text}")
        
        return "\n".join(text_parts)
    
    def _format_objections(self, objections: List[Dict[str, Any]]) -> str:
        """Formata obje√ß√µes para o prompt"""
        if not objections:
            return "Nenhuma obje√ß√£o detectada"
        
        formatted = []
        for obj in objections:
            obj_type = obj.get("type", "unknown")
            handled = "RESOLVIDA" if obj.get("handled", False) else "PENDENTE"
            suggestion = obj.get("suggestion", "")
            formatted.append(f"- {obj_type.upper()}: {handled} - {suggestion}")
        
        return "\n".join(formatted)
    
    def _parse_llm_response(self, llm_response: str, call_id: str = "unknown") -> CallSummary:
        """Parseia resposta do LLM em estrutura CallSummary"""
        try:
            # Extrair JSON da resposta do LLM
            json_start = llm_response.find('{')
            json_end = llm_response.rfind('}') + 1
            json_str = llm_response[json_start:json_end]

            if json_str:
                data = json.loads(json_str)

                return CallSummary(
                    call_id=call_id,
                    key_points=data.get("key_points", []),
                    objections=data.get("objections", []),
                    next_steps=data.get("next_steps", []),
                    metrics=data.get("metrics", {}),
                    generated_at=datetime.now().timestamp()
                )
            else:
                # Resposta n√£o cont√©m JSON
                raise json.JSONDecodeError("No JSON found in response", llm_response, 0)

        except (json.JSONDecodeError, KeyError) as e:
            # Fallback em caso de erro no parsing
            self.logger.warning(f"Erro ao parsear resposta LLM: {e}")
            return CallSummary(
                call_id=call_id,
                key_points=["Resumo gerado automaticamente"],
                objections=[],
                next_steps=[{
                    "desc": "Revisar chamada e criar follow-up",
                    "due": "2025-01-20",
                    "owner": "vendedor"
                }],
                metrics={
                    "talk_time_vendor_pct": 50.0,
                    "talk_time_client_pct": 50.0,
                    "sentiment_avg": 0.7,
                    "objections_total": 0,
                    "objections_resolved": 0,
                    "buying_signals": 1
                },
                generated_at=datetime.now().timestamp()
            )
    
    async def get(self, call_id: str) -> Optional[CallSummary]:
        """Recupera resumo existente"""
        summary_data = await self.storage_service.get_summary(call_id)
        if summary_data:
            return CallSummary(**summary_data)
        return None
    
    async def export(self, call_id: str, format: str = "md") -> str:
        """Exporta resumo em formato espec√≠fico"""
        summary = await self.get(call_id)
        if not summary:
            raise ValueError(f"Resumo n√£o encontrado para call_id: {call_id}")
        
        if format == "md":
            return self._export_markdown(summary)
        elif format == "pdf":
            return await self._export_pdf(summary)
        else:
            raise ValueError(f"Formato n√£o suportado: {format}")
    
    def _export_markdown(self, summary: CallSummary) -> str:
        """Exporta resumo em Markdown"""
        md = f"""# Resumo da Chamada

## Pontos Principais
"""
        for point in summary.key_points:
            md += f"- {point}\n"
        
        md += "\n## Obje√ß√µes\n"
        for obj in summary.objections:
            status = "‚úÖ" if obj.get("handled") else "‚ùå"
            md += f"- {status} **{obj.get('type', '').upper()}**: {obj.get('note', '')}\n"
        
        md += "\n## Pr√≥ximos Passos\n"
        for step in summary.next_steps:
            due = f" (vence: {step.get('due')})" if step.get('due') else ""
            owner = f" - {step.get('owner')}" if step.get('owner') else ""
            md += f"- [ ] {step.get('desc', '')}{due}{owner}\n"
        
        md += "\n## M√©tricas\n"
        metrics = summary.metrics
        md += f"- Tempo de fala vendedor: {metrics.get('talk_time_vendor_pct', 0):.1f}%\n"
        md += f"- Tempo de fala cliente: {metrics.get('talk_time_client_pct', 0):.1f}%\n"
        md += f"- Sentimento m√©dio: {metrics.get('sentiment_avg', 0):.2f}\n"
        md += f"- Obje√ß√µes: {metrics.get('objections_total', 0)} (resolvidas: {metrics.get('objections_resolved', 0)})\n"
        md += f"- Sinais de compra: {metrics.get('buying_signals', 0)}\n"
        
        return md
    
    async def _export_pdf(self, summary: CallSummary) -> str:
        """Exporta resumo em PDF (placeholder)"""
        # TODO: Implementar gera√ß√£o de PDF
        # Por enquanto retorna markdown
        return self._export_markdown(summary)
