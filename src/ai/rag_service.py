"""
RAG Service - Obje√ß√µes e Sugest√µes
======================================

Servi√ßo respons√°vel por detectar obje√ß√µes e gerar sugest√µes
usando o LLMService local.
"""

import logging
from typing import List, Dict, Any, Optional
from dataclasses import dataclass
from PyQt6.QtCore import QObject, pyqtSignal

# Classes b√°sicas
@dataclass
class RAGPassage:
    id: str
    content: str
    score: float = 0.0

@dataclass
class RAGResult:
    passages: List[RAGPassage]
    suggestions: List[str]

@dataclass
class ObjectionEvent:
    text: str
    category: str
    confidence: float = 0.0

# Decorator placeholder para cache (implementa√ß√£o futura)
def cache_result(ttl=300, priority=8, key_prefix=""):
    def decorator(func):
        return func
    return decorator

class RAGService(QObject):
    """Servi√ßo RAG para detec√ß√£o de obje√ß√µes e gera√ß√£o de sugest√µes."""
    
    suggestions_ready = pyqtSignal(object)
    rag_error = pyqtSignal(str)
    
    def __init__(self, config, llm_service):
        super().__init__()
        self.config = config
        self.llm_service = llm_service
        self.logger = logging.getLogger(__name__)
        self.is_available = False
        self._check_availability()
        
        # Base de conhecimento real com cache
        self._init_knowledge_base()
        self._init_cache()
    
    def _check_availability(self):
        """Verificar disponibilidade do AnythingLLM."""
        self.is_available = self.anythingllm_client.health_check()
        self.llm_status_changed.emit(self.is_available)
        
        if self.is_available:
            self.logger.info("‚úÖ AnythingLLM dispon√≠vel para RAG")
        else:
            self.logger.warning("‚ö†Ô∏è AnythingLLM n√£o dispon√≠vel - usando fallback")
    
    def _init_knowledge_base(self):
        """Inicializar base de conhecimento real."""
        try:
            # Tentar carregar de arquivo JSON
            knowledge_file = self.config.app_dir / "data" / "knowledge_base.json"
            if knowledge_file.exists():
                with open(knowledge_file, 'r', encoding='utf-8') as f:
                    self.knowledge_base = json.load(f)
                self.logger.info(f"‚úÖ Base de conhecimento carregada: {len(self.knowledge_base)} itens")
            else:
                # Fallback para base simulada se arquivo n√£o existir
                self._create_default_knowledge_base()
                self._save_knowledge_base()
                
        except Exception as e:
            self.logger.error(f"Erro ao carregar base de conhecimento: {e}")
            self._create_default_knowledge_base()
    
    def _create_default_knowledge_base(self):
        """Criar base de conhecimento padr√£o."""
        self.knowledge_base = [
            {
                "id": "preco_001",
                "title": "Estrat√©gias de Pre√ßo",
                "content": "Quando o cliente menciona que o pre√ßo est√° alto, foque no valor percebido. Apresente o ROI e os benef√≠cios de longo prazo. Compare com alternativas mais caras no mercado.",
                "category": "preco",
                "keywords": ["pre√ßo", "custo", "valor", "or√ßamento", "caro", "investimento"],
                "priority": 1.0
            },
            {
                "id": "preco_002", 
                "title": "Flexibilidade de Pagamento",
                "content": "Ofere√ßa op√ß√µes de pagamento flex√≠veis: parcelamento, desconto por pagamento √† vista, ou planos de assinatura. Mostre como isso se adapta ao or√ßamento do cliente.",
                "category": "preco",
                "keywords": ["pagamento", "parcelamento", "desconto", "flex√≠vel", "plano"],
                "priority": 0.9
            },
            {
                "id": "timing_001",
                "title": "Urg√™ncia e Timing",
                "content": "Crie senso de urg√™ncia mostrando oportunidades limitadas, promo√ß√µes por tempo determinado, ou riscos de perder benef√≠cios. Use dados de mercado para justificar.",
                "category": "timing",
                "keywords": ["timing", "urg√™ncia", "prazo", "tempo", "agora", "depois"],
                "priority": 0.8
            },
            {
                "id": "autoridade_001",
                "title": "Tomada de Decis√£o",
                "content": "Identifique quem realmente toma a decis√£o. Pergunte sobre o processo de aprova√ß√£o e ofere√ßa-se para falar com os stakeholders. Prepare materiais para diferentes n√≠veis.",
                "category": "autoridade",
                "keywords": ["autoridade", "decis√£o", "chefe", "aprovador", "stakeholder"],
                "priority": 0.9
            },
            {
                "id": "necessidade_001",
                "title": "Descoberta de Necessidades",
                "content": "Use perguntas abertas para descobrir necessidades n√£o atendidas. Relacione sua solu√ß√£o aos problemas espec√≠ficos do cliente. Mostre casos de sucesso similares.",
                "category": "necessidade",
                "keywords": ["necessidade", "problema", "dor", "solu√ß√£o", "benef√≠cio"],
                "priority": 0.8
            },
            {
                "id": "geral_001",
                "title": "T√©cnica de Espelho",
                "content": "Repita a obje√ß√£o do cliente para confirmar entendimento. Isso demonstra empatia e pode revelar informa√ß√µes adicionais sobre a preocupa√ß√£o real.",
                "category": "geral",
                "keywords": ["empatia", "entendimento", "confirma√ß√£o", "espelho"],
                "priority": 0.7
            }
        ]
    
    def _save_knowledge_base(self):
        """Salvar base de conhecimento em arquivo."""
        try:
            knowledge_file = self.config.app_dir / "data" / "knowledge_base.json"
            knowledge_file.parent.mkdir(exist_ok=True)
            
            with open(knowledge_file, 'w', encoding='utf-8') as f:
                json.dump(self.knowledge_base, f, ensure_ascii=False, indent=2)
            
            self.logger.info(f"‚úÖ Base de conhecimento salva: {knowledge_file}")
            
        except Exception as e:
            self.logger.error(f"Erro ao salvar base de conhecimento: {e}")
    
    def _init_cache(self):
        """Inicializar cache para melhorar performance."""
        self.cache = {}
        self.cache_ttl = 300  # 5 minutos
        self.cache_stats = {"hits": 0, "misses": 0}
    
    @cache_result(ttl=300, priority=8, key_prefix="rag_passages")
    def retrieve_passages(self, objection_text: str, category: str, top_k: int = 3) -> List[RAGPassage]:
        """
        Recuperar passagens relevantes da base de conhecimento com cache e busca sem√¢ntica melhorada.
        
        Args:
            objection_text: Texto da obje√ß√£o
            category: Categoria da obje√ß√£o
            top_k: N√∫mero de passagens a retornar
            
        Returns:
            Lista de passagens ordenadas por relev√¢ncia
        """
        # Verificar cache primeiro
        cache_key = f"{objection_text.lower()}_{category}_{top_k}"
        if cache_key in self.cache:
            cache_entry = self.cache[cache_key]
            if time.time() - cache_entry["timestamp"] < self.cache_ttl:
                self.cache_stats["hits"] += 1
                return cache_entry["passages"]
        
        self.cache_stats["misses"] += 1
        
        # Busca sem√¢ntica melhorada
        relevant_passages = []
        scored_passages = []
        
        # Normalizar texto da obje√ß√£o
        objection_words = set(objection_text.lower().split())
        
        for passage in self.knowledge_base:
            score = 0.0
            
            # 1. Score por categoria (maior peso)
            if passage['category'] == category:
                score += 0.4
            
            # 2. Score por palavras-chave espec√≠ficas
            if 'keywords' in passage:
                keyword_matches = objection_words.intersection(set(passage['keywords']))
                score += len(keyword_matches) * 0.3
            
            # 3. Score por matching de palavras no conte√∫do
            content_words = set(passage['content'].lower().split())
            word_matches = objection_words.intersection(content_words)
            score += len(word_matches) * 0.2
            
            # 4. Score por prioridade do item
            if 'priority' in passage:
                score += passage['priority'] * 0.1
            
            # 5. Score por relev√¢ncia sem√¢ntica (palavras relacionadas)
            semantic_matches = self._calculate_semantic_similarity(objection_text, passage['content'])
            score += semantic_matches * 0.2
            
            if score > 0:
                scored_passages.append((passage, score))
        
        # Ordenar por score e pegar top-k
        scored_passages.sort(key=lambda x: x[1], reverse=True)
        
        for passage, score in scored_passages[:top_k]:
            relevant_passages.append(RAGPassage(
                id=passage['id'],
                title=passage['title'],
                snippet=passage['content'],
                score=score
            ))
        
        # Armazenar no cache
        self.cache[cache_key] = {
            "passages": relevant_passages,
            "timestamp": time.time()
        }
        
        return relevant_passages
    
    def _calculate_semantic_similarity(self, text1: str, text2: str) -> float:
        """Calcular similaridade sem√¢ntica entre dois textos."""
        try:
            # Implementa√ß√£o simples baseada em palavras relacionadas
            # Em produ√ß√£o, usar embeddings ou modelos de similaridade
            
            # Palavras relacionadas para vendas
            related_words = {
                "pre√ßo": ["custo", "valor", "or√ßamento", "investimento", "caro", "barato"],
                "timing": ["tempo", "prazo", "urg√™ncia", "agora", "depois", "esperar"],
                "autoridade": ["decis√£o", "chefe", "aprovador", "stakeholder", "respons√°vel"],
                "necessidade": ["problema", "dor", "solu√ß√£o", "benef√≠cio", "resultado"],
                "cliente": ["comprador", "usu√°rio", "consumidor", "prospect"],
                "venda": ["negocia√ß√£o", "proposta", "oferta", "fechamento"]
            }
            
            words1 = set(text1.lower().split())
            words2 = set(text2.lower().split())
            
            # Calcular similaridade direta
            direct_similarity = len(words1.intersection(words2)) / max(len(words1), len(words2), 1)
            
            # Calcular similaridade por palavras relacionadas
            related_similarity = 0.0
            for word1 in words1:
                for category, related in related_words.items():
                    if word1 in related:
                        for word2 in words2:
                            if word2 in related:
                                related_similarity += 0.1
                                break
            
            return min(1.0, direct_similarity + related_similarity)
            
        except Exception as e:
            self.logger.warning(f"Erro no c√°lculo de similaridade: {e}")
            return 0.0
    
    def process_objection(
        self, 
        objection_event: ObjectionEvent,
        stream_callback: Optional[callable] = None
    ):
        """
        Processar obje√ß√£o detectada e gerar sugest√µes.
        
        Args:
            objection_event: Evento de obje√ß√£o
            stream_callback: Callback para streaming de texto
        """
        try:
            # 1. Recuperar passagens relevantes
            passages = self.retrieve_passages(
                objection_event.text,
                objection_event.category,
                top_k=3
            )
            
            if not passages:
                self.logger.warning("Nenhuma passagem relevante encontrada")
                # Criar resposta de fallback
                fallback_result = RAGResult(
                    call_id=objection_event.call_id,
                    objection=objection_event,
                    suggestions=[
                        Suggestion(
                            text="N√£o encontramos informa√ß√µes espec√≠ficas para esta obje√ß√£o. Considere perguntar mais sobre as preocupa√ß√µes do cliente.",
                            score=0.5,
                            sources=[]
                        )
                    ],
                    retrieved_passages=[],
                    latency_ms=0.0,
                    model_info={"provider": "fallback", "model": "no-rag", "temperature": 0.0}
                )
                self.suggestions_ready.emit(fallback_result)
                return
            
            # 2. Processar em thread separada
            self.rag_worker.process_objection(objection_event, passages, stream_callback)
            
        except Exception as e:
            self.logger.error(f"Erro ao processar obje√ß√£o: {e}")
            self.rag_error.emit(f"Erro no processamento: {e}")
    
    def _on_rag_complete(self, result: RAGResult):
        """Callback quando RAG √© completado."""
        self.logger.info(f"‚úÖ RAG completado em {result.latency_ms:.0f}ms")
        self.suggestions_ready.emit(result)
    
    def _on_rag_error(self, error: str):
        """Callback quando RAG falha."""
        self.logger.error(f"‚ùå Erro no RAG: {error}")
        self.rag_error.emit(error)
    
    def generate_session_summary(
        self, 
        session_data: Dict[str, Any],
        stream_callback: Optional[callable] = None
    ) -> str:
        """
        Gerar resumo da sess√£o usando AnythingLLM.
        
        Args:
            session_data: Dados da sess√£o
            stream_callback: Callback para streaming
            
        Returns:
            Resumo estruturado
        """
        if not self.is_available:
            return "AnythingLLM n√£o dispon√≠vel para gera√ß√£o de resumo."
        
        try:
            return self.anythingllm_client.generate_session_summary(
                session_data, stream_callback
            )
        except Exception as e:
            self.logger.error(f"Erro ao gerar resumo: {e}")
            return "Erro ao gerar resumo da sess√£o."
    
    def health_check(self) -> bool:
        """Verificar sa√∫de do servi√ßo RAG."""
        return self.is_available
    
    def get_cache_stats(self) -> Dict[str, Any]:
        """Obter estat√≠sticas do cache."""
        total_requests = self.cache_stats["hits"] + self.cache_stats["misses"]
        hit_rate = self.cache_stats["hits"] / total_requests if total_requests > 0 else 0.0
        
        return {
            "hits": self.cache_stats["hits"],
            "misses": self.cache_stats["misses"],
            "hit_rate": hit_rate,
            "cache_size": len(self.cache),
            "cache_ttl": self.cache_ttl
        }
    
    def clear_cache(self):
        """Limpar cache."""
        self.cache.clear()
        self.cache_stats = {"hits": 0, "misses": 0}
        self.logger.info("‚úÖ Cache limpo")
    
    def cleanup(self):
        """Limpa recursos."""
        self.logger.info("üßπ Limpando RAGService...") 