"""
NPU Manager - Gerenciador da NPU Snapdragon
===========================================

Coordena todos os modelos ONNX rodando na NPU para
processamento simult√¢neo de √°udio e an√°lise.
Integra com ModelManager para carregamento unificado.
"""

import logging
import numpy as np
from typing import Dict, Any, Optional
from PyQt6.QtCore import QObject, pyqtSignal, QThread, QTimer

try:
    import onnxruntime as ort
except ImportError:
    ort = None


class NPUWorkerThread(QThread):
    """Thread worker para processamento NPU."""
    
    result_ready = pyqtSignal(str, dict)  # model_name, result
    
    def __init__(self, model_name: str, model_path: str, input_data: Any):
        super().__init__()
        self.model_name = model_name
        self.model_path = model_path
        self.input_data = input_data
        self.session = None
    
    def run(self):
        """Executar infer√™ncia na NPU."""
        try:
            # TODO: Implementar infer√™ncia real
            # Por enquanto, simular resultado
            if self.model_name == "whisper":
                result = {
                    "text": "Texto transcrito de exemplo",
                    "confidence": 0.95,
                    "speaker_id": "vendor"
                }
            elif self.model_name == "sentiment":
                result = {
                    "sentiment": 0.72,
                    "emotion": "positive",
                    "engagement": 0.85
                }
            else:
                result = {"status": "processed"}
            
            self.result_ready.emit(self.model_name, result)
            
        except Exception as e:
            logging.error(f"Erro no worker NPU {self.model_name}: {e}")


class NPUManager(QObject):
    """Gerenciador principal da NPU."""
    
    # Sinais
    transcription_ready = pyqtSignal(str, str)  # texto, speaker_id
    sentiment_updated = pyqtSignal(dict)        # m√©tricas
    objection_detected = pyqtSignal(str, list) # obje√ß√£o, sugest√µes
    npu_status_changed = pyqtSignal(str)        # status
    
    def __init__(self, config, model_manager=None):
        super().__init__()
        self.config = config
        self.model_manager = model_manager
        self.logger = logging.getLogger(__name__)
        
        # Estado da NPU
        self.is_initialized = False
        self.available_providers = []
        self.loaded_models = {}
        self.active_workers = {}
        
        # Timer para simular processamento cont√≠nuo
        self.processing_timer = QTimer()
        self.processing_timer.timeout.connect(self._simulate_processing)
    
    def initialize(self):
        """Inicializar NPU e carregar modelos."""
        try:
            self.logger.info("üß† Inicializando NPU Manager...")
            
            # Verificar disponibilidade do ONNX Runtime
            if not ort:
                raise ImportError("ONNX Runtime n√£o dispon√≠vel")
            
            # Verificar providers dispon√≠veis
            self._check_available_providers()
            
            # Carregar modelos essenciais
            self._load_models()
            
            self.is_initialized = True
            self.npu_status_changed.emit("connected")
            self.logger.info("‚úÖ NPU Manager inicializado")
            
        except Exception as e:
            self.logger.error(f"‚ùå Erro ao inicializar NPU: {e}")
            self.npu_status_changed.emit("error")
            # Continuar em modo simula√ß√£o
            self._enable_simulation_mode()
    
    def _check_available_providers(self):
        """Verificar providers ONNX dispon√≠veis."""
        self.available_providers = ort.get_available_providers()
        self.logger.info(f"Providers dispon√≠veis: {self.available_providers}")
        
        # Verificar se QNN Provider est√° dispon√≠vel
        if "QNNExecutionProvider" in self.available_providers:
            self.logger.info("‚úÖ QNN Execution Provider detectado (NPU)")
        else:
            self.logger.warning("‚ö†Ô∏è QNN Provider n√£o encontrado, usando CPU/GPU")
    
    def _load_models(self):
        """Carregar modelos ONNX na NPU."""
        if self.model_manager:
            # Usar ModelManager se dispon√≠vel
            self.model_manager.load_manifest()
            
            # Carregar modelos essenciais
            essential_models = ["whisper_base", "distilbert_sentiment", "bert_objection"]
            
            for model_name in essential_models:
                try:
                    session = self.model_manager.load_model_session(model_name)
                    if session:
                        self.loaded_models[model_name] = {
                            "session": session,
                            "status": "loaded"
                        }
                        self.logger.info(f"‚úÖ Modelo {model_name} carregado via ModelManager")
                    else:
                        self.logger.warning(f"‚ö†Ô∏è Modelo {model_name} n√£o p√¥de ser carregado")
                except Exception as e:
                    self.logger.error(f"‚ùå Erro ao carregar {model_name}: {e}")
        else:
            # Fallback para carregamento manual
            models_to_load = {
                "whisper": "whisper-base.onnx",
                "sentiment": "distilbert-sentiment.onnx", 
                "objection": "bert-objection.onnx",
                "speaker": "ecapa-speaker.onnx"
            }
            
            for model_name, filename in models_to_load.items():
                model_path = self.config.get_model_path(filename)
                
                if model_path.exists():
                    try:
                        # TODO: Carregar modelo real
                        # session = ort.InferenceSession(str(model_path), providers=...)
                        self.loaded_models[model_name] = {
                            "path": model_path,
                            "status": "loaded"
                        }
                        self.logger.info(f"‚úÖ Modelo {model_name} carregado")
                    except Exception as e:
                        self.logger.error(f"‚ùå Erro ao carregar {model_name}: {e}")
                else:
                    self.logger.warning(f"‚ö†Ô∏è Modelo {filename} n√£o encontrado")
    
    def _enable_simulation_mode(self):
        """Habilitar modo de simula√ß√£o."""
        self.logger.info("üé≠ Habilitando modo de simula√ß√£o NPU")
        self.is_initialized = True
        self.npu_status_changed.emit("simulation")
        
        # Simular modelos carregados
        self.loaded_models = {
            "whisper": {"status": "simulated"},
            "sentiment": {"status": "simulated"},
            "objection": {"status": "simulated"},
            "speaker": {"status": "simulated"}
        }
    
    def process_audio(self, audio_data: np.ndarray):
        """Processar √°udio atrav√©s da pipeline NPU."""
        if not self.is_initialized:
            return
        
        try:
            # Iniciar processamento ass√≠ncrono para m√∫ltiplos modelos
            self._process_transcription(audio_data)
            self._process_sentiment_analysis(audio_data)
            self._process_objection_detection(audio_data)
            
        except Exception as e:
            self.logger.error(f"Erro no processamento de √°udio: {e}")
    
    def _process_transcription(self, audio_data: np.ndarray):
        """Processar transcri√ß√£o via Whisper."""
        if "whisper" not in self.loaded_models:
            return
        
        # Criar worker thread para Whisper
        worker = NPUWorkerThread("whisper", "", audio_data)
        worker.result_ready.connect(self._handle_transcription_result)
        worker.start()
        
        self.active_workers["whisper"] = worker
    
    def _process_sentiment_analysis(self, audio_data: np.ndarray):
        """Processar an√°lise de sentimento."""
        if "sentiment" not in self.loaded_models:
            return
        
        worker = NPUWorkerThread("sentiment", "", audio_data)
        worker.result_ready.connect(self._handle_sentiment_result)
        worker.start()
        
        self.active_workers["sentiment"] = worker
    
    def _process_objection_detection(self, audio_data: np.ndarray):
        """Processar detec√ß√£o de obje√ß√µes."""
        if "objection" not in self.loaded_models:
            return
        
        # TODO: Implementar detec√ß√£o real de obje√ß√µes
        pass
    
    def _handle_transcription_result(self, model_name: str, result: dict):
        """Processar resultado da transcri√ß√£o."""
        if model_name == "whisper":
            text = result.get("text", "")
            speaker_id = result.get("speaker_id", "unknown")
            
            if text.strip():
                self.transcription_ready.emit(text, speaker_id)
                
                # Verificar se h√° obje√ß√µes no texto
                self._check_for_objections(text)
    
    def _handle_sentiment_result(self, model_name: str, result: dict):
        """Processar resultado da an√°lise de sentimento."""
        if model_name == "sentiment":
            self.sentiment_updated.emit(result)
    
    def _check_for_objections(self, text: str):
        """Verificar obje√ß√µes no texto e sugerir respostas."""
        objection_keywords = ["caro", "pre√ßo", "barato", "concorrente", "pensar"]
        
        text_lower = text.lower()
        for keyword in objection_keywords:
            if keyword in text_lower:
                # Simular sugest√µes
                suggestions = [
                    {
                        "text": f"Entendo sua preocupa√ß√£o sobre {keyword}. Vamos falar sobre o valor...",
                        "confidence": 0.9,
                        "category": "Obje√ß√£o de Pre√ßo"
                    },
                    {
                        "text": "Posso mostrar um case de sucesso similar ao seu...",
                        "confidence": 0.85,
                        "category": "Prova Social"
                    }
                ]
                
                self.objection_detected.emit(keyword, suggestions)
                break
    
    def _simulate_processing(self):
        """Simular processamento cont√≠nuo para demo."""
        # Simular transcri√ß√£o peri√≥dica
        import random
        
        sample_texts = [
            "Estou interessado na sua solu√ß√£o",
            "Qual √© o pre√ßo do sistema?",
            "Preciso conversar com minha equipe",
            "Isso parece interessante"
        ]
        
        if random.random() < 0.3:  # 30% chance
            text = random.choice(sample_texts)
            speaker = random.choice(["vendor", "client"])
            self.transcription_ready.emit(text, speaker)
    
    def start_demo_mode(self):
        """Iniciar modo de demonstra√ß√£o."""
        self.processing_timer.start(5000)  # A cada 5 segundos
    
    def stop_demo_mode(self):
        """Parar modo de demonstra√ß√£o."""
        self.processing_timer.stop()
    
    def cleanup(self):
        """Limpar recursos da NPU."""
        self.logger.info("üîÑ Limpando recursos NPU...")
        
        # Parar workers ativos
        for worker in self.active_workers.values():
            if worker.isRunning():
                worker.quit()
                worker.wait()
        
        self.active_workers.clear()
        self.loaded_models.clear()
        self.stop_demo_mode()
        
        # Limpar ModelManager se dispon√≠vel
        if self.model_manager:
            self.model_manager.cleanup()
        
        self.logger.info("‚úÖ NPU Manager finalizado")
