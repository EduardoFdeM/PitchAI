"""
Script para preparar estrutura de modelos ONNX
============================================

Este script cria a estrutura necessÃ¡ria para os modelos ONNX
e documenta como integrar quando os modelos estiverem disponÃ­veis.
"""

import os
import shutil
from pathlib import Path
import json


def create_models_structure():
    """Criar estrutura de diretÃ³rios para modelos."""
    
    print("ðŸ“ Criando estrutura de modelos...")
    
    # DiretÃ³rio base
    models_dir = Path("models")
    models_dir.mkdir(exist_ok=True)
    
    # SubdiretÃ³rios
    (models_dir / "whisper").mkdir(exist_ok=True)
    (models_dir / "sentiment").mkdir(exist_ok=True)
    (models_dir / "objection").mkdir(exist_ok=True)
    (models_dir / "speaker").mkdir(exist_ok=True)
    (models_dir / "llm").mkdir(exist_ok=True)
    
    print("âœ… Estrutura de diretÃ³rios criada")
    
    # Criar arquivo de configuraÃ§Ã£o
    config = {
        "models": {
            "whisper": {
                "file": "whisper_base.onnx",
                "description": "Modelo Whisper para transcriÃ§Ã£o de Ã¡udio",
                "input_format": "audio PCM 16-bit, 16kHz, mono",
                "output_format": "texto transcrito",
                "expected_size_mb": 150,
                "providers": ["QNNExecutionProvider", "CPUExecutionProvider"]
            },
            "sentiment": {
                "file": "distilbert_sentiment.onnx",
                "description": "Modelo DistilBERT para anÃ¡lise de sentimento",
                "input_format": "texto tokenizado",
                "output_format": "score de sentimento (-1 a 1)",
                "expected_size_mb": 260,
                "providers": ["QNNExecutionProvider", "CPUExecutionProvider"]
            },
            "objection": {
                "file": "bert_objection.onnx",
                "description": "Modelo BERT para detecÃ§Ã£o de objeÃ§Ãµes",
                "input_format": "texto tokenizado",
                "output_format": "categoria de objeÃ§Ã£o + confianÃ§a",
                "expected_size_mb": 420,
                "providers": ["QNNExecutionProvider", "CPUExecutionProvider"]
            },
            "speaker": {
                "file": "ecapa_speaker.onnx",
                "description": "Modelo ECAPA para identificaÃ§Ã£o de falantes",
                "input_format": "audio PCM 16-bit, 16kHz, mono",
                "output_format": "embedding de speaker + confianÃ§a",
                "expected_size_mb": 90,
                "providers": ["QNNExecutionProvider", "CPUExecutionProvider"]
            },
            "llm": {
                "file": "anythingllm_local.onnx",
                "description": "Modelo LLM local para geraÃ§Ã£o de texto",
                "input_format": "prompt tokenizado",
                "output_format": "texto gerado",
                "expected_size_mb": 2000,
                "providers": ["QNNExecutionProvider", "CPUExecutionProvider"]
            }
        },
        "integration_notes": {
            "setup": [
                "1. Colocar modelos ONNX na pasta models/",
                "2. Verificar se os nomes dos arquivos correspondem ao config",
                "3. Executar src/main_frontend.py",
                "4. Verificar logs para confirmaÃ§Ã£o de carregamento"
            ],
            "testing": [
                "1. Iniciar gravaÃ§Ã£o na aplicaÃ§Ã£o",
                "2. Falar algumas frases",
                "3. Verificar se transcriÃ§Ã£o aparece",
                "4. Verificar se sentimento Ã© detectado",
                "5. Verificar se objeÃ§Ãµes sÃ£o identificadas"
            ],
            "troubleshooting": [
                "Se modelos nÃ£o carregarem:",
                "- Verificar se arquivos existem na pasta models/",
                "- Verificar se ONNX Runtime estÃ¡ instalado",
                "- Verificar logs para erros especÃ­ficos",
                "- Verificar se providers estÃ£o disponÃ­veis"
            ]
        }
    }
    
    # Salvar configuraÃ§Ã£o
    with open(models_dir / "models_config.json", "w", encoding="utf-8") as f:
        json.dump(config, f, indent=2, ensure_ascii=False)
    
    print("âœ… Arquivo de configuraÃ§Ã£o criado")
    
    # Criar README
    readme_content = """# Modelos ONNX - PitchAI

## ðŸ“ Estrutura de DiretÃ³rios

```
models/
â”œâ”€â”€ whisper_base.onnx          # TranscriÃ§Ã£o de Ã¡udio
â”œâ”€â”€ distilbert_sentiment.onnx  # AnÃ¡lise de sentimento
â”œâ”€â”€ bert_objection.onnx        # DetecÃ§Ã£o de objeÃ§Ãµes
â”œâ”€â”€ ecapa_speaker.onnx         # IdentificaÃ§Ã£o de falantes
â”œâ”€â”€ anythingllm_local.onnx     # LLM local
â””â”€â”€ models_config.json         # ConfiguraÃ§Ã£o dos modelos
```

## ðŸš€ Como Integrar

### 1. PreparaÃ§Ã£o
- Coloque os modelos ONNX na pasta `models/`
- Verifique se os nomes dos arquivos correspondem ao config
- Certifique-se de que o ONNX Runtime estÃ¡ instalado

### 2. ExecuÃ§Ã£o
```bash
# Ativar ambiente virtual
source venv/bin/activate

# Executar aplicaÃ§Ã£o
python src/main_frontend.py
```

### 3. VerificaÃ§Ã£o
- Verifique os logs para confirmaÃ§Ã£o de carregamento
- Teste a funcionalidade de gravaÃ§Ã£o
- Confirme se os modelos estÃ£o funcionando

## ðŸ”§ ConfiguraÃ§Ã£o

Os modelos sÃ£o configurados automaticamente no `NPUManager`. 
Para ajustar parÃ¢metros, edite `src/ai/npu_manager.py`.

### ParÃ¢metros AjustÃ¡veis:
- `audio_buffer_size`: Tamanho do buffer de Ã¡udio (ms)
- `sentiment_window`: Janela de anÃ¡lise de sentimento (s)
- `objection_threshold`: Threshold para detecÃ§Ã£o de objeÃ§Ãµes
- `sentiment_sensitivity`: Sensibilidade do sentimento

## ðŸ“Š Status dos Modelos

A aplicaÃ§Ã£o mostrarÃ¡ o status de cada modelo:
- âœ… Carregado: Modelo funcionando
- âš ï¸ SimulaÃ§Ã£o: Modelo nÃ£o encontrado, usando simulaÃ§Ã£o
- âŒ Erro: Problema no carregamento

## ðŸ› Troubleshooting

### Modelos nÃ£o carregam:
1. Verificar se arquivos existem na pasta `models/`
2. Verificar se ONNX Runtime estÃ¡ instalado
3. Verificar logs para erros especÃ­ficos
4. Verificar se providers estÃ£o disponÃ­veis

### Performance lenta:
1. Verificar se NPU estÃ¡ sendo usada
2. Ajustar tamanhos de buffer
3. Verificar uso de CPU/GPU

### Erros de inferÃªncia:
1. Verificar formato de entrada dos modelos
2. Verificar compatibilidade de versÃµes
3. Verificar logs de erro especÃ­ficos

## ðŸ“ Notas TÃ©cnicas

- **Formato de Ãudio**: PCM 16-bit, 16kHz, mono
- **Formato de Texto**: UTF-8
- **Providers**: QNN (NPU) > CoreML > CPU
- **Cache**: Resultados sÃ£o cacheados por 5 segundos
- **Threading**: Processamento assÃ­ncrono para nÃ£o bloquear UI

## ðŸ”„ AtualizaÃ§Ãµes

Para atualizar modelos:
1. Substituir arquivos ONNX na pasta `models/`
2. Reiniciar aplicaÃ§Ã£o
3. Verificar logs de carregamento
4. Testar funcionalidade

## ðŸ“ž Suporte

Em caso de problemas:
1. Verificar logs da aplicaÃ§Ã£o
2. Consultar documentaÃ§Ã£o ONNX Runtime
3. Verificar compatibilidade de hardware
"""
    
    with open(models_dir / "README.md", "w", encoding="utf-8") as f:
        f.write(readme_content)
    
    print("âœ… README criado")
    
    # Criar arquivos placeholder
    placeholders = [
        "whisper_base.onnx",
        "distilbert_sentiment.onnx", 
        "bert_objection.onnx",
        "ecapa_speaker.onnx",
        "anythingllm_local.onnx"
    ]
    
    for placeholder in placeholders:
        placeholder_path = models_dir / placeholder
        if not placeholder_path.exists():
            with open(placeholder_path, "w") as f:
                f.write(f"# Placeholder para {placeholder}\n")
                f.write("# Substitua este arquivo pelo modelo ONNX real\n")
            print(f"ðŸ“„ Placeholder criado: {placeholder}")
    
    print("\nðŸŽ¯ Estrutura de modelos preparada!")
    print("ðŸ“‹ PrÃ³ximos passos:")
    print("1. Substituir placeholders pelos modelos ONNX reais")
    print("2. Executar src/main_frontend.py")
    print("3. Verificar logs de carregamento")
    print("4. Testar funcionalidade")


if __name__ == "__main__":
    create_models_structure()
