# Feature 3 â€” AnÃ¡lise de Sentimento Multi-Dimensional
## Plano de ImplementaÃ§Ã£o Detalhado

### ğŸ“‹ **VisÃ£o Geral**
ImplementaÃ§Ã£o da Feature 3 que combina anÃ¡lise de texto, prosÃ³dia e expressÃµes faciais para inferir sentimento e engajamento do cliente em tempo real.

---

## ğŸ¯ **Objetivos da ImplementaÃ§Ã£o**

### **Principais:**
- âœ… Inferir sentimento (-1 a +1) e engajamento (0 a 1) em tempo real
- âœ… Detectar palavras-gatilho e gerar alertas contextuais
- âœ… Dashboard visual com mÃ©tricas e sparklines
- âœ… IntegraÃ§Ã£o com Features 1 e 2 (Ã¡udio + transcriÃ§Ã£o)
- âœ… ExecuÃ§Ã£o na NPU para baixa latÃªncia (â‰¤ 500ms)

### **SecundÃ¡rios:**
- âœ… Suporte opcional a anÃ¡lise facial (opt-in)
- âœ… FusÃ£o configurÃ¡vel de mÃºltiplas fontes
- âœ… PersistÃªncia para Features 5 e 6
- âœ… DegradaÃ§Ã£o graciosa sem vÃ­deo

---

## ğŸ—ï¸ **Arquitetura da ImplementaÃ§Ã£o**

### **Estrutura de Arquivos:**
```
src/ai/
â”œâ”€â”€ sentiment/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ sentiment_service.py      # ServiÃ§o principal
â”‚   â”œâ”€â”€ text_analyzer.py          # RF-3.1: Motor textual
â”‚   â”œâ”€â”€ prosody_analyzer.py       # RF-3.2: Motor de prosÃ³dia
â”‚   â”œâ”€â”€ vision_analyzer.py        # RF-3.3: Motor de visÃ£o (opcional)
â”‚   â”œâ”€â”€ fusion_engine.py          # RF-3.4: FusÃ£o de dados
â”‚   â”œâ”€â”€ keyword_detector.py       # DetecÃ§Ã£o de palavras-gatilho
â”‚   â””â”€â”€ models/
â”‚       â”œâ”€â”€ distilbert_sentiment.onnx
â”‚       â”œâ”€â”€ prosody_classifier.onnx
â”‚       â””â”€â”€ face_expression.onnx
```

### **Componentes Principais:**

#### **1. SentimentService (sentiment_service.py)**
```python
class SentimentService(QObject):
    """ServiÃ§o principal de anÃ¡lise de sentimento."""
    
    # Sinais
    sentiment_updated = pyqtSignal(SentimentSample)
    alert_triggered = pyqtSignal(SentimentEvent)
    dashboard_updated = pyqtSignal(DashboardData)
    
    def __init__(self, config, model_manager):
        self.text_analyzer = TextAnalyzer()
        self.prosody_analyzer = ProsodyAnalyzer()
        self.vision_analyzer = VisionAnalyzer()  # opcional
        self.fusion_engine = FusionEngine()
        self.keyword_detector = KeywordDetector()
```

#### **2. TextAnalyzer (text_analyzer.py)**
```python
class TextAnalyzer:
    """RF-3.1: Motor textual (NLP)"""
    
    def analyze_sentiment(self, text: str) -> float:
        """Inferir sentimento de texto (-1 a +1)."""
        
    def detect_keywords(self, text: str) -> List[KeywordMatch]:
        """Detectar palavras-gatilho."""
        
    def calculate_engagement(self, text: str) -> float:
        """Calcular engajamento textual."""
```

#### **3. ProsodyAnalyzer (prosody_analyzer.py)**
```python
class ProsodyAnalyzer:
    """RF-3.2: Motor de prosÃ³dia (Ã¡udio)"""
    
    def extract_features(self, audio: np.ndarray) -> ProsodyFeatures:
        """Extrair F0, energia, ritmo."""
        
    def classify_valence(self, features: ProsodyFeatures) -> float:
        """Classificar valÃªncia (-1 a +1)."""
        
    def detect_micro_expressions(self, features: ProsodyFeatures) -> List[str]:
        """Detectar micro-expressÃµes vocais."""
```

#### **4. VisionAnalyzer (vision_analyzer.py)**
```python
class VisionAnalyzer:
    """RF-3.3: Motor de visÃ£o (opcional)"""
    
    def __init__(self, opt_in: bool = False):
        self.enabled = opt_in
        
    def detect_faces(self, frame: np.ndarray) -> List[Face]:
        """Detectar faces na imagem."""
        
    def classify_expressions(self, faces: List[Face]) -> List[Expression]:
        """Classificar expressÃµes faciais."""
```

#### **5. FusionEngine (fusion_engine.py)**
```python
class FusionEngine:
    """RF-3.4: FusÃ£o de dados"""
    
    def __init__(self, weights: Dict[str, float] = None):
        self.weights = weights or {"text": 0.5, "voice": 0.3, "vision": 0.2}
        
    def fuse_sentiment(self, text_score: float, voice_score: float, 
                      vision_score: Optional[float] = None) -> float:
        """Fundir scores de sentimento."""
        
    def fuse_engagement(self, text_eng: float, voice_eng: float,
                       vision_eng: Optional[float] = None) -> float:
        """Fundir scores de engajamento."""
```

---

## ğŸ“Š **Modelo de Dados**

### **Estruturas Principais:**
```python
@dataclass
class SentimentSample:
    """Amostra de sentimento conforme SRS."""
    id: str
    call_id: str
    ts_start_ms: int
    ts_end_ms: int
    score_valence: float          # -1..+1
    score_engagement: float       # 0..1
    weights: Dict[str, float]     # pesos usados na fusÃ£o
    details: Dict[str, Any]       # confidences, features, labels

@dataclass
class SentimentEvent:
    """Evento de sentimento (alerta, sinal)."""
    id: str
    call_id: str
    ts_ms: int
    kind: str                     # 'buying_signal'|'risk'|'keyword'|'alert'
    label: str                    # "preco", "ROI", "piloto"
    strength: float               # 0..1

@dataclass
class DashboardData:
    """Dados para o dashboard em tempo real."""
    sentiment_percent: int        # 0-100
    engagement_percent: int       # 0-100
    buying_signals_count: int
    alerts: List[Dict[str, Any]]
    sparkline_data: List[float]   # Ãºltimos 90s
```

### **Schema SQL:**
```sql
-- Tabela de amostras de sentimento
CREATE TABLE sentiment_sample (
  id TEXT PRIMARY KEY,
  call_id TEXT NOT NULL,
  ts_start_ms INTEGER NOT NULL,
  ts_end_ms INTEGER NOT NULL,
  score_valence REAL NOT NULL,   -- -1..+1
  score_engagement REAL,         -- 0..1
  src_text REAL,                 -- peso usado na fusÃ£o
  src_voice REAL,
  src_vision REAL,
  details_json TEXT,             -- confidences, features, labels
  FOREIGN KEY (call_id) REFERENCES call(id) ON DELETE CASCADE
);

-- Tabela de eventos de sentimento
CREATE TABLE sentiment_event (
  id TEXT PRIMARY KEY,
  call_id TEXT NOT NULL,
  ts_ms INTEGER NOT NULL,
  kind TEXT,         -- buying_signal|risk|keyword|alert
  label TEXT,        -- "preco", "ROI", "piloto"
  strength REAL,     -- 0..1
  FOREIGN KEY (call_id) REFERENCES call(id) ON DELETE CASCADE
);
```

---

## ğŸ”„ **Fluxo de Processamento**

### **Pipeline Principal:**
```
[Feature 2: TranscriptChunk] â†’ [TextAnalyzer] â†’ [SentimentScore]
[Feature 1: AudioChunk] â†’ [ProsodyAnalyzer] â†’ [ValenceScore]
[Video Frame] â†’ [VisionAnalyzer] â†’ [ExpressionScore] (opcional)
                                    â†“
[FusionEngine] â†’ [SentimentSample] â†’ [Dashboard] + [Storage]
                                    â†“
[KeywordDetector] â†’ [SentimentEvent] â†’ [Alert] + [Storage]
```

### **SequÃªncia Detalhada:**
1. **Receber dados** das Features 1 e 2
2. **Processar em paralelo** na NPU:
   - Texto â†’ sentimento + keywords
   - Ãudio â†’ prosÃ³dia + micro-expressÃµes
   - VÃ­deo â†’ expressÃµes faciais (se habilitado)
3. **Fundir resultados** com pesos configurÃ¡veis
4. **Gerar amostra** de sentimento
5. **Detectar alertas** e sinais de compra
6. **Atualizar dashboard** em tempo real
7. **Persistir dados** para histÃ³rico

---

## ğŸ¨ **Interface do Dashboard**

### **Componente UI (sentiment_widget.py):**
```python
class SentimentWidget(QWidget):
    """Widget do dashboard de sentimento."""
    
    def __init__(self):
        super().__init__()
        self.setup_ui()
        
    def setup_ui(self):
        """Configurar interface."""
        # Layout principal
        layout = QVBoxLayout()
        
        # MÃ©tricas principais
        self.sentiment_label = QLabel("ğŸ˜Š Sentimento: 72%")
        self.engagement_label = QLabel("ğŸ¯ Engajamento: 85%")
        self.signals_label = QLabel("âš¡ Sinais de compra: 3")
        
        # Sparklines (Ãºltimos 90s)
        self.sentiment_sparkline = SparklineWidget()
        self.engagement_sparkline = SparklineWidget()
        
        # Alertas
        self.alerts_list = QListWidget()
        
        # ConfiguraÃ§Ãµes
        self.vision_checkbox = QCheckBox("AnÃ¡lise facial (opt-in)")
```

### **Design Visual:**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ğŸ˜Š Sentimento: 72% positivo        â”‚
â”‚ ğŸ¯ Engajamento: 85% alto           â”‚
â”‚ âš¡ Sinais de compra: 3 detectados  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ğŸ“ˆ HistÃ³rico (90s):                â”‚
â”‚ Sentimento: â–â–‚â–ƒâ–…â–‚â–â–‚â–ƒâ–…â–‚â–           â”‚
â”‚ Engajamento: â–â–‚â–ƒâ–…â–‚â–â–‚â–ƒâ–…â–‚â–          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ğŸš¨ Alertas:                        â”‚
â”‚ â€¢ "preÃ§o" mencionado 2x            â”‚
â”‚ â€¢ "contrato" mencionado 1x         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## âš™ï¸ **ConfiguraÃ§Ã£o e Modelos**

### **Modelos ONNX NecessÃ¡rios:**
```json
{
  "distilbert_sentiment": {
    "path": "models/distilbert_sentiment.onnx",
    "ep": ["QNN", "CPU"],
    "input": "text_tokens",
    "quant": "int8_fp16",
    "description": "DistilBERT para anÃ¡lise de sentimento",
    "size_mb": 65,
    "latency_target_ms": 30
  },
  "prosody_classifier": {
    "path": "models/prosody_classifier.onnx",
    "ep": ["QNN", "CPU"],
    "input": "audio_features",
    "quant": "int8_fp16",
    "description": "Classificador de prosÃ³dia",
    "size_mb": 25,
    "latency_target_ms": 20
  },
  "face_expression": {
    "path": "models/face_expression.onnx",
    "ep": ["QNN", "CPU"],
    "input": "face_image",
    "quant": "int8_fp16",
    "description": "Classificador de expressÃµes faciais",
    "size_mb": 45,
    "latency_target_ms": 40
  }
}
```

### **ConfiguraÃ§Ãµes:**
```python
@dataclass
class SentimentConfig:
    """ConfiguraÃ§Ãµes de sentimento."""
    # Pesos de fusÃ£o
    text_weight: float = 0.5
    voice_weight: float = 0.3
    vision_weight: float = 0.2
    
    # Janelas de anÃ¡lise
    text_window_s: float = 5.0
    prosody_window_s: float = 3.0
    vision_window_s: float = 1.0
    
    # Thresholds
    sentiment_threshold: float = 0.1
    engagement_threshold: float = 0.3
    alert_threshold: float = 0.7
    
    # Palavras-gatilho
    keywords: List[str] = field(default_factory=lambda: [
        "preÃ§o", "custo", "caro", "barato",
        "contrato", "acordo", "termos",
        "prazo", "tempo", "urgente",
        "piloto", "teste", "demonstraÃ§Ã£o",
        "ROI", "retorno", "investimento"
    ])
```

---

## ğŸ§ª **Testes e ValidaÃ§Ã£o**

### **Testes UnitÃ¡rios:**
```python
# test_sentiment_service.py
def test_text_analyzer():
    """Testar anÃ¡lise de texto."""
    analyzer = TextAnalyzer()
    score = analyzer.analyze_sentiment("Estou muito satisfeito")
    assert -1 <= score <= 1

def test_prosody_analyzer():
    """Testar anÃ¡lise de prosÃ³dia."""
    analyzer = ProsodyAnalyzer()
    features = analyzer.extract_features(audio_sample)
    assert features.f0 > 0

def test_fusion_engine():
    """Testar fusÃ£o de dados."""
    engine = FusionEngine()
    fused = engine.fuse_sentiment(0.8, 0.6, 0.7)
    assert -1 <= fused <= 1
```

### **Testes de IntegraÃ§Ã£o:**
```python
# test_sentiment_integration.py
def test_end_to_end_latency():
    """Testar latÃªncia end-to-end â‰¤ 500ms."""
    service = SentimentService(config)
    start_time = time.time()
    
    # Simular entrada
    service.process_text_chunk(text_chunk)
    service.process_audio_chunk(audio_chunk)
    
    # Aguardar resultado
    result = service.get_latest_sentiment()
    latency = (time.time() - start_time) * 1000
    
    assert latency <= 500  # ms
```

### **Testes de Performance:**
```python
def test_npu_utilization():
    """Testar uso da NPU."""
    # Monitorar uso de CPU/GPU durante inferÃªncia
    # Deve ser â‰¤ 10% CPU, â‰ˆ 0% GPU
```

---

## ğŸ“… **Cronograma de ImplementaÃ§Ã£o**

### **Fase 1: FundaÃ§Ã£o (Semana 1)**
- [ ] Criar estrutura de arquivos
- [ ] Implementar TextAnalyzer bÃ¡sico
- [ ] Implementar ProsodyAnalyzer bÃ¡sico
- [ ] Criar modelos de dados
- [ ] Testes unitÃ¡rios bÃ¡sicos

### **Fase 2: Core (Semana 2)**
- [ ] Implementar FusionEngine
- [ ] Implementar KeywordDetector
- [ ] Integrar com ModelManager
- [ ] Implementar SentimentService principal
- [ ] Testes de integraÃ§Ã£o

### **Fase 3: UI e Polimento (Semana 3)**
- [ ] Implementar SentimentWidget
- [ ] Criar dashboard visual
- [ ] Implementar sparklines
- [ ] Adicionar configuraÃ§Ãµes de opt-in
- [ ] Testes de UI

### **Fase 4: OtimizaÃ§Ã£o (Semana 4)**
- [ ] Otimizar para NPU
- [ ] Ajustar latÃªncia
- [ ] Implementar VisionAnalyzer (opcional)
- [ ] Testes de performance
- [ ] DocumentaÃ§Ã£o final

---

## ğŸ¯ **CritÃ©rios de Sucesso**

### **Funcionais:**
- [ ] RF-3.1 a RF-3.6 implementados
- [ ] Dashboard em tempo real funcionando
- [ ] DetecÃ§Ã£o de palavras-gatilho â‰¥ 90% precisÃ£o
- [ ] FusÃ£o de mÃºltiplas fontes configurÃ¡vel

### **NÃ£o-Funcionais:**
- [ ] LatÃªncia â‰¤ 500ms (P95)
- [ ] Uso CPU â‰¤ 10% durante inferÃªncia
- [ ] DegradaÃ§Ã£o graciosa sem vÃ­deo
- [ ] Opt-in/opt-out para anÃ¡lise facial

### **IntegraÃ§Ã£o:**
- [ ] CompatÃ­vel com Features 1 e 2
- [ ] Dados persistidos para Features 5 e 6
- [ ] EventBus funcionando
- [ ] ModelManager integrado

---

## ğŸš€ **PrÃ³ximos Passos**

1. **Iniciar Fase 1** - Criar estrutura bÃ¡sica
2. **Configurar modelos ONNX** - DistilBERT, prosÃ³dia, face
3. **Implementar TextAnalyzer** - Primeiro componente
4. **Testar integraÃ§Ã£o** - Com Features 1 e 2
5. **Iterar e otimizar** - Baseado em feedback

---

## ğŸ“š **ReferÃªncias TÃ©cnicas**

- **DistilBERT**: https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english
- **ProsÃ³dia**: https://github.com/facebookresearch/fairseq/tree/main/examples/wav2vec
- **ExpressÃµes Faciais**: https://github.com/opencv/opencv_contrib/tree/master/modules/face
- **ONNX Runtime**: https://onnxruntime.ai/docs/execution-providers/QNN-ExecutionProvider.html
- **PyQt6**: https://doc.qt.io/qtforpython-6/

---

*Este plano estÃ¡ alinhado com o SRS v1.0 da Feature 3 e integra-se perfeitamente com as Features 1 e 2 jÃ¡ implementadas.* 