#!/usr/bin/env python3
"""
Teste da Feature 2 - Transcri√ß√£o em Tempo Real
=============================================

Teste para verificar se a transcri√ß√£o Whisper est√° funcionando:
- Integra√ß√£o com Feature 1 (AudioCapture)
- Streaming por janelas 3-5s
- Eventos em tempo real
- Lat√™ncia ‚â§ 500ms
"""

import sys
import time
import logging
from pathlib import Path

# Adicionar src ao path
sys.path.insert(0, str(Path(__file__).parent / "src"))

from core.config import Config
from audio.capture import AudioCapture, AudioChunk
from ai.asr_whisper import TranscriptionService, TranscriptChunk
from ai.model_manager import ModelManager

def setup_logging():
    """Configurar logging."""
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )

def test_feature2_transcription():
    """Testar a Feature 2 - Transcri√ß√£o em Tempo Real."""
    print("üß™ Testando Feature 2 - Transcri√ß√£o em Tempo Real")
    print("=" * 60)
    
    config = Config()
    
    # Inicializar Model Manager
    model_manager = ModelManager(config)
    model_manager.load_manifest()
    
    # Obter entrada do modelo Whisper
    whisper_entry = model_manager.get_model_entry("whisper_base")
    if not whisper_entry:
        print("‚ö†Ô∏è Modelo Whisper n√£o encontrado no manifesto, usando simula√ß√£o")
        whisper_entry = {
            "path": "models/whisper_base.onnx",
            "ep": ["CPU"],
            "input": "audio_16k_mono"
        }
    
    # Inicializar componentes
    audio_capture = AudioCapture(config)
    transcription_service = TranscriptionService(config, whisper_entry, model_manager=model_manager)
    
    # Contadores para m√©tricas
    audio_chunks_received = {"mic": 0, "loopback": 0}
    transcript_chunks_received = {"mic": 0, "loopback": 0}
    latencies = []
    call_ids = set()
    
    def on_audio_chunk(chunk: AudioChunk):
        """Callback para chunks de √°udio da Feature 1."""
        audio_chunks_received[chunk.source] += 1
        call_ids.add(chunk.call_id)
        
        # Enviar para transcri√ß√£o
        transcription_service.push_audio_chunk(chunk)
        
        # Log peri√≥dico
        if sum(audio_chunks_received.values()) % 20 == 0:
            print(f"üìä √Åudio: mic={audio_chunks_received['mic']}, loopback={audio_chunks_received['loopback']}")
    
    def on_transcript_chunk(chunk: TranscriptChunk):
        """Callback para chunks de transcri√ß√£o."""
        transcript_chunks_received[chunk.source] += 1
        
        # Calcular lat√™ncia (simplificado)
        current_time = int(time.monotonic_ns() / 1_000_000)
        latency = current_time - chunk.ts_end_ms
        latencies.append(latency)
        
        # Log de transcri√ß√£o
        print(f"üìù {chunk.source.upper()}: '{chunk.text}' (conf: {chunk.confidence:.2f}, lat: {latency}ms)")
        
        # Verificar lat√™ncia
        if latency > 500:
            print(f"‚ö†Ô∏è Lat√™ncia alta: {latency}ms > 500ms")
    
    def on_transcription_started(call_id: str):
        """Callback para in√≠cio de transcri√ß√£o."""
        print(f"üé§ Transcri√ß√£o iniciada: {call_id}")
    
    def on_transcription_stopped(call_id: str):
        """Callback para fim de transcri√ß√£o."""
        print(f"‚èπÔ∏è Transcri√ß√£o parada: {call_id}")
    
    def on_error(error: str):
        """Callback para erros."""
        print(f"‚ùå Erro: {error}")
    
    try:
        # Inicializar componentes
        print("üîß Inicializando componentes...")
        audio_capture.initialize()
        transcription_service.initialize()
        
        # Conectar callbacks
        audio_capture.add_callback(on_audio_chunk)
        transcription_service.transcript_chunk_ready.connect(on_transcript_chunk)
        transcription_service.transcription_started.connect(on_transcription_started)
        transcription_service.transcription_stopped.connect(on_transcription_stopped)
        transcription_service.error_occurred.connect(on_error)
        
        # Iniciar captura e transcri√ß√£o
        print("üé§ Iniciando captura e transcri√ß√£o...")
        audio_capture.start()
        transcription_service.start("test_call_001")
        
        # Aguardar captura
        print("‚è≥ Capturando e transcrevendo por 10 segundos...")
        print("   (Fale algo no microfone e reproduza √°udio no sistema)")
        time.sleep(10)
        
        # Parar componentes
        print("‚èπÔ∏è Parando componentes...")
        transcription_service.stop("test_call_001")
        audio_capture.stop()
        
        # An√°lise dos resultados
        print("\nüìä AN√ÅLISE DA FEATURE 2")
        print("=" * 40)
        
        # 1. Integra√ß√£o com Feature 1
        print("1Ô∏è‚É£ Integra√ß√£o com Feature 1:")
        total_audio = sum(audio_chunks_received.values())
        total_transcripts = sum(transcript_chunks_received.values())
        print(f"   Chunks de √°udio recebidos: {total_audio}")
        print(f"   Chunks de transcri√ß√£o gerados: {total_transcripts}")
        print(f"   Call IDs √∫nicos: {len(call_ids)}")
        
        if total_audio > 0:
            print("   ‚úÖ Integra√ß√£o com Feature 1 funcionando")
        else:
            print("   ‚ùå Nenhum chunk de √°udio recebido")
        
        # 2. Streaming por janelas
        print("\n2Ô∏è‚É£ Streaming por janelas:")
        for source in ["mic", "loopback"]:
            count = transcript_chunks_received[source]
            print(f"   {source}: {count} chunks transcritos")
            if count > 0:
                print(f"   ‚úÖ {source} funcionando")
            else:
                print(f"   ‚ö†Ô∏è {source} n√£o funcionou")
        
        # 3. Lat√™ncia
        print("\n3Ô∏è‚É£ Lat√™ncia:")
        if latencies:
            avg_latency = sum(latencies) / len(latencies)
            max_latency = max(latencies)
            min_latency = min(latencies)
            
            print(f"   M√©dia: {avg_latency:.1f}ms")
            print(f"   M√°xima: {max_latency}ms")
            print(f"   M√≠nima: {min_latency}ms")
            
            if avg_latency <= 500:
                print("   ‚úÖ Lat√™ncia m√©dia ‚â§ 500ms (requisito atendido)")
            else:
                print(f"   ‚ö†Ô∏è Lat√™ncia m√©dia > 500ms: {avg_latency:.1f}ms")
            
            if max_latency <= 1000:
                print("   ‚úÖ Lat√™ncia m√°xima ‚â§ 1000ms")
            else:
                print(f"   ‚ö†Ô∏è Lat√™ncia m√°xima > 1000ms: {max_latency}ms")
        else:
            print("   ‚ö†Ô∏è Nenhuma medi√ß√£o de lat√™ncia")
        
        # 4. M√©tricas do servi√ßo
        print("\n4Ô∏è‚É£ M√©tricas do servi√ßo:")
        metrics = transcription_service.get_metrics()
        print(f"   Chunks processados: {metrics['chunks_processed']}")
        print(f"   Lat√™ncia m√©dia: {metrics['avg_latency_ms']:.1f}ms")
        print(f"   √öltima lat√™ncia: {metrics['last_latency_ms']:.1f}ms")
        print(f"   Buffer sizes: {metrics['buffer_sizes']}")
        
        # 5. Model Manager
        print("\n5Ô∏è‚É£ Model Manager:")
        models = model_manager.list_models()
        print(f"   Modelos dispon√≠veis: {models}")
        
        whisper_info = model_manager.get_model_info("whisper_base")
        if whisper_info:
            print(f"   Whisper: {whisper_info['description']}")
            print(f"   Tamanho: {whisper_info['size_mb']}MB")
            print(f"   Lat√™ncia alvo: {whisper_info['latency_target_ms']}ms")
            print(f"   Carregado: {whisper_info['loaded']}")
        else:
            print("   ‚ö†Ô∏è Informa√ß√µes do Whisper n√£o dispon√≠veis")
        
        return True
        
    except Exception as e:
        print(f"‚ùå Erro no teste: {e}")
        import traceback
        traceback.print_exc()
        return False
    finally:
        # Limpar recursos
        transcription_service.cleanup()
        audio_capture.cleanup()
        model_manager.cleanup()

def main():
    """Fun√ß√£o principal."""
    print("üöÄ PitchAI - Teste da Feature 2 - Transcri√ß√£o em Tempo Real")
    print("=" * 80)
    
    setup_logging()
    
    success = test_feature2_transcription()
    
    if success:
        print("\nüéâ FEATURE 2 IMPLEMENTADA COM SUCESSO!")
        print("   ‚úÖ Integra√ß√£o com Feature 1")
        print("   ‚úÖ Streaming por janelas 3-5s")
        print("   ‚úÖ Eventos em tempo real")
        print("   ‚úÖ Lat√™ncia ‚â§ 500ms")
        print("   ‚úÖ Model Manager integrado")
    else:
        print("\n‚ùå Teste falhou.")

if __name__ == "__main__":
    main() 