"""
Teste das OtimizaÃ§Ãµes de Performance
===================================

Testa as melhorias implementadas:
- Monitoramento de performance
- Cache inteligente
- Profiling de operaÃ§Ãµes
- OtimizaÃ§Ãµes de memÃ³ria
"""

import sys
import time
import threading
import numpy as np
from pathlib import Path

# Adicionar src ao path
sys.path.insert(0, str(Path(__file__).parent.parent / "src"))

from core.config import create_config
from core.performance_monitor import PerformanceMonitor, profile_operation
from core.cache_manager import CacheManager, cache_result


def test_performance_monitoring():
    """Testar monitoramento de performance."""
    print("ğŸ” Testando monitoramento de performance...")
    
    config = create_config()
    monitor = PerformanceMonitor(config)
    monitor.start_monitoring()
    
    # Simular operaÃ§Ãµes lentas
    @profile_operation("slow_operation", "test")
    def slow_function():
        time.sleep(0.1)  # 100ms
        return "result"
    
    @profile_operation("fast_operation", "test")
    def fast_function():
        time.sleep(0.01)  # 10ms
        return "result"
    
    # Executar operaÃ§Ãµes
    for i in range(10):
        slow_function()
        fast_function()
    
    # Aguardar monitoramento
    time.sleep(2)
    
    # Verificar mÃ©tricas
    summary = monitor.get_performance_summary()
    print(f"   OperaÃ§Ãµes monitoradas: {summary['total_operations']}")
    print(f"   Alertas gerados: {summary['total_alerts']}")
    
    # Verificar operaÃ§Ãµes lentas
    slow_ops = summary['slow_operations']
    if slow_ops:
        print(f"   OperaÃ§Ã£o mais lenta: {slow_ops[0][0]} ({slow_ops[0][1]['avg_time']:.3f}s)")
    
    # Verificar mÃ©tricas do sistema
    system_metrics = summary['system_metrics']
    if system_metrics:
        print(f"   CPU: {system_metrics.get('cpu_percent', 0):.1f}%")
        print(f"   MemÃ³ria: {system_metrics.get('memory_mb', 0):.1f}MB")
        print(f"   Threads: {system_metrics.get('thread_count', 0)}")
    
    # Detectar memory leaks
    leaks = monitor.detect_memory_leaks()
    print(f"   PossÃ­veis memory leaks: {len(leaks)}")
    
    # Obter recomendaÃ§Ãµes
    recommendations = monitor.get_recommendations()
    print(f"   RecomendaÃ§Ãµes: {len(recommendations)}")
    for rec in recommendations[:3]:
        print(f"     - {rec}")
    
    monitor.stop_monitoring()
    
    return summary['total_operations'] > 0


def test_cache_performance():
    """Testar performance do cache."""
    print("\nğŸ’¾ Testando performance do cache...")
    
    config = create_config()
    cache_manager = CacheManager(config)
    
    # Testar cache de funÃ§Ãµes
    @cache_result(ttl=60, priority=8, key_prefix="test_cache")
    def expensive_function(param: str):
        time.sleep(0.05)  # Simular operaÃ§Ã£o cara
        return f"result_{param}"
    
    # Primeira execuÃ§Ã£o (cache miss)
    start_time = time.time()
    result1 = expensive_function("test1")
    time1 = (time.time() - start_time) * 1000
    
    # Segunda execuÃ§Ã£o (cache hit)
    start_time = time.time()
    result2 = expensive_function("test1")
    time2 = (time.time() - start_time) * 1000
    
    print(f"   Primeira execuÃ§Ã£o: {time1:.1f}ms")
    print(f"   Segunda execuÃ§Ã£o (cache): {time2:.1f}ms")
    print(f"   Melhoria: {time1/time2:.1f}x mais rÃ¡pido")
    
    # Verificar estatÃ­sticas
    stats = cache_manager.get_stats()
    print(f"   Cache hits: {stats['total_hits']}")
    print(f"   Cache misses: {stats['total_misses']}")
    
    # Testar diferentes nÃ­veis
    cache_manager.set("test_key", "test_value", ttl=30, priority=5)
    retrieved = cache_manager.get("test_key")
    print(f"   Cache get/set: {'âœ…' if retrieved == 'test_value' else 'âŒ'}")
    
    return time2 < time1 * 0.5  # Cache deve ser pelo menos 2x mais rÃ¡pido


def test_concurrent_performance():
    """Testar performance concorrente."""
    print("\nâš¡ Testando performance concorrente...")
    
    config = create_config()
    monitor = PerformanceMonitor(config)
    monitor.start_monitoring()
    
    results = []
    lock = threading.Lock()
    
    @profile_operation("concurrent_operation", "test")
    def concurrent_function(thread_id: int):
        time.sleep(0.02)  # 20ms
        with lock:
            results.append(f"thread_{thread_id}")
        return f"result_{thread_id}"
    
    # Executar operaÃ§Ãµes concorrentes
    threads = []
    start_time = time.time()
    
    for i in range(10):
        thread = threading.Thread(
            target=concurrent_function, 
            args=(i,),
            name=f"worker_{i}"
        )
        threads.append(thread)
        thread.start()
    
    # Aguardar conclusÃ£o
    for thread in threads:
        thread.join()
    
    total_time = (time.time() - start_time) * 1000
    
    print(f"   Tempo total: {total_time:.1f}ms")
    print(f"   OperaÃ§Ãµes concluÃ­das: {len(results)}")
    print(f"   Throughput: {len(results)/total_time*1000:.1f} ops/s")
    
    # Verificar mÃ©tricas
    summary = monitor.get_performance_summary()
    system_metrics = summary['system_metrics']
    if system_metrics:
        print(f"   Threads ativos: {system_metrics.get('thread_count', 0)}")
    
    monitor.stop_monitoring()
    
    return len(results) == 10


def test_memory_optimization():
    """Testar otimizaÃ§Ã£o de memÃ³ria."""
    print("\nğŸ§¹ Testando otimizaÃ§Ã£o de memÃ³ria...")
    
    config = create_config()
    monitor = PerformanceMonitor(config)
    monitor.start_monitoring()
    
    # Simular uso de memÃ³ria
    large_data = []
    
    @profile_operation("memory_operation", "test")
    def memory_intensive_function():
        # Alocar memÃ³ria
        data = np.random.rand(1000, 1000)  # ~8MB
        large_data.append(data)
        time.sleep(0.01)
        return data.shape
    
    # Executar operaÃ§Ãµes que consomem memÃ³ria
    for i in range(5):
        memory_intensive_function()
    
    # Verificar uso de memÃ³ria antes da otimizaÃ§Ã£o
    summary_before = monitor.get_performance_summary()
    system_before = summary_before['system_metrics']
    memory_before = system_before.get('memory_mb', 0) if system_before else 0
    
    print(f"   MemÃ³ria antes: {memory_before:.1f}MB")
    
    # Otimizar memÃ³ria
    monitor.optimize_memory()
    
    # Verificar uso de memÃ³ria depois da otimizaÃ§Ã£o
    time.sleep(1)  # Aguardar garbage collection
    summary_after = monitor.get_performance_summary()
    system_after = summary_after['system_metrics']
    memory_after = system_after.get('memory_mb', 0) if system_after else 0
    
    print(f"   MemÃ³ria depois: {memory_after:.1f}MB")
    print(f"   DiferenÃ§a: {memory_before - memory_after:.1f}MB")
    
    # Detectar memory leaks
    leaks = monitor.detect_memory_leaks()
    print(f"   Memory leaks detectados: {len(leaks)}")
    
    monitor.stop_monitoring()
    
    return memory_after <= memory_before


def test_cache_intelligence():
    """Testar inteligÃªncia do cache."""
    print("\nğŸ§  Testando inteligÃªncia do cache...")
    
    config = create_config()
    cache_manager = CacheManager(config)
    
    # Simular padrÃµes de acesso
    access_patterns = [
        "user_profile_123",
        "user_profile_123",  # Repetido
        "product_info_456",
        "user_profile_123",  # Repetido novamente
        "order_history_789",
        "product_info_456",  # Repetido
    ]
    
    @cache_result(ttl=300, priority=6, key_prefix="smart_cache")
    def smart_function(key: str):
        time.sleep(0.03)  # Simular operaÃ§Ã£o cara
        return f"data_for_{key}"
    
    # Simular acessos
    for key in access_patterns:
        smart_function(key)
    
    # Verificar estatÃ­sticas
    stats = cache_manager.get_stats()
    hit_rate = stats['total_hits'] / (stats['total_hits'] + stats['total_misses']) if (stats['total_hits'] + stats['total_misses']) > 0 else 0
    
    print(f"   Total de acessos: {stats['total_hits'] + stats['total_misses']}")
    print(f"   Cache hits: {stats['total_hits']}")
    print(f"   Hit rate: {hit_rate:.1%}")
    
    # Testar prefetch
    cache_manager.prefetch("user_profile_124")  # PadrÃ£o similar
    
    # Verificar prefetch
    prefetch_stats = cache_manager.get_stats()
    print(f"   Prefetch patterns: {prefetch_stats['prefetch_patterns']}")
    print(f"   Prefetch cache size: {prefetch_stats['prefetch_cache_size']}")
    
    return hit_rate > 0.3  # Pelo menos 30% de hit rate


def main():
    """Executar todos os testes de performance."""
    print("ğŸš€ Teste das OtimizaÃ§Ãµes de Performance")
    print("=" * 50)
    
    try:
        # Teste 1: Monitoramento de performance
        monitoring_ok = test_performance_monitoring()
        
        # Teste 2: Performance do cache
        cache_ok = test_cache_performance()
        
        # Teste 3: Performance concorrente
        concurrent_ok = test_concurrent_performance()
        
        # Teste 4: OtimizaÃ§Ã£o de memÃ³ria
        memory_ok = test_memory_optimization()
        
        # Teste 5: InteligÃªncia do cache
        intelligence_ok = test_cache_intelligence()
        
        # Resumo
        print("\nğŸ“Š Resumo dos Testes:")
        print(f"   Monitoramento: {'âœ…' if monitoring_ok else 'âŒ'}")
        print(f"   Cache Performance: {'âœ…' if cache_ok else 'âŒ'}")
        print(f"   Performance Concorrente: {'âœ…' if concurrent_ok else 'âŒ'}")
        print(f"   OtimizaÃ§Ã£o de MemÃ³ria: {'âœ…' if memory_ok else 'âŒ'}")
        print(f"   InteligÃªncia do Cache: {'âœ…' if intelligence_ok else 'âŒ'}")
        
        all_passed = all([monitoring_ok, cache_ok, concurrent_ok, memory_ok, intelligence_ok])
        
        if all_passed:
            print("\nğŸ‰ Todas as otimizaÃ§Ãµes de performance estÃ£o funcionando!")
            print("âœ… Sistema mais rÃ¡pido e eficiente")
        else:
            print("\nâš ï¸ Algumas otimizaÃ§Ãµes precisam de ajustes")
        
    except Exception as e:
        print(f"\nâŒ Erro durante os testes: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main() 